{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeries-Helper-Code.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk+W1Bfv/FHSgl9Vqr+XXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azedfahad/data-science/blob/master/TimeSeries_Helper_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVJsjROi45CA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ceO3Nk2YGpzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bMZRUV5cGp18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering to create the additional explanaotry variables"
      ],
      "metadata": {
        "id": "HYZCSUA7Gqbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['year'] = data['date_time'].apply(lambda x: x[:4])\n",
        "data['month'] = data['date_time'].apply(lambda x: x[5:7])\n",
        "data['weekday'] = pd.to_datetime(data['date_time']).apply(lambda x: x.weekday())\n",
        "data['hour'] = pd.to_datetime(data['date_time']).apply(lambda x: x.hour)\n",
        "data['isholiday'] = (data['holiday'] == 'None').apply(float)"
      ],
      "metadata": {
        "id": "KoPkuBOQ47mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FY5oZR0cHkls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the default XGBoost model"
      ],
      "metadata": {
        "id": "z52ITOcpHN2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create objects X and y\n",
        "X = data[['year', 'month', 'weekday', 'hour', 'isholiday']]\n",
        "y = data['traffic_volume']\n",
        "\n",
        "# Create Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=12345, shuffle=False)\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "my_xgb = XGBRegressor()\n",
        "my_xgb.fit(X_train, y_train)\n",
        "\n",
        "xgb_fcst = my_xgb.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(list(y_test), list(xgb_fcst)))"
      ],
      "metadata": {
        "id": "Z1EEiExWHCvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the default LightGBM model"
      ],
      "metadata": {
        "id": "R8EcPGo4H0AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "my_lgbm = LGBMRegressor()\n",
        "my_lgbm.fit(X_train, y_train)\n",
        "\n",
        "lgbm_fcst = my_lgbm.predict(X_test)\n",
        "\n",
        "print(r2_score(list(y_test), list(lgbm_fcst)))"
      ],
      "metadata": {
        "id": "uFW-Uz_cHDAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a graph to compare the XGBoost and LightGBM forecast to the actuals"
      ],
      "metadata": {
        "id": "rUxOSfRrH7N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(list(y_test))\n",
        "plt.plot(list(xgb_fcst))\n",
        "plt.plot(list(lgbm_fcst))\n",
        "plt.legend(['actual', 'xgb forecast', 'lgbm forecast'])\n",
        "plt.ylabel('Traffic Volume')\n",
        "plt.xlabel('Steps in test data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CicjlmVYH_By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying a Bayesian Optimization to the xgboost"
      ],
      "metadata": {
        "id": "eCjU4MM_ICJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "xgb_opt = BayesSearchCV(\n",
        "    XGBRegressor(),\n",
        "    {\n",
        "        'learning_rate': (10e-6, 1.0, 'log-uniform'),\n",
        "        'max_depth': Integer(0, 50, 'uniform'),\n",
        "        'n_estimators' : (10, 1000, 'log-uniform'),\n",
        "    },\n",
        "    n_iter=10,\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "xgb_opt.fit(X_train, y_train)\n",
        "xgb_tuned_fcst = opt.best_estimator_.predict(X_test)\n",
        "r2_score(list(y_test), list(xgb_tuned_fcst))"
      ],
      "metadata": {
        "id": "IE291UPeIGzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying a Bayesian Optimization to the LightGBM"
      ],
      "metadata": {
        "id": "cWQPXbUyIKIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "lgbm_opt = BayesSearchCV(\n",
        "    LGBMRegressor(),\n",
        "    {\n",
        "        'learning_rate': (10e-6, 1.0, 'log-uniform'),\n",
        "        'max_depth': Integer(-1, 50, 'uniform'),\n",
        "        'n_estimators' : (10, 1000, 'log-uniform'),\n",
        "    },\n",
        "    n_iter=10,\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "lgbm_opt.fit(X_train, y_train)\n",
        "\n",
        "lgbm_tuned_fcst = lgbm_opt.best_estimator_.predict(X_test)\n",
        "r2_score(list(y_test), list(lgbm_tuned_fcst))"
      ],
      "metadata": {
        "id": "-PrsFiDOINtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the two tuned models"
      ],
      "metadata": {
        "id": "cW6rXggdIQbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(list(y_test))\n",
        "plt.plot(list(xgb_tuned_fcst))\n",
        "plt.plot(list(lgbm_tuned_fcst))\n",
        "plt.legend(['actual', 'xgb forecast', 'lgbm forecast'])\n",
        "plt.ylabel('Traffic Volume')\n",
        "plt.xlabel('Steps in test data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vtcrUy70ITyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisations"
      ],
      "metadata": {
        "id": "xoFFEFw1IV27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perc_on_bar(feature):\n",
        "    '''\n",
        "    plot\n",
        "    feature: categorical feature\n",
        "    the function won't work if a column is passed in hue parameter\n",
        "    '''\n",
        "    #Creating a countplot for the feature\n",
        "    sns.set(rc={'figure.figsize':(15,7)})\n",
        "    ax=sns.countplot(x=feature, data=data)\n",
        "    \n",
        "    total = len(feature) # length of the column\n",
        "    for p in ax.patches:\n",
        "        percentage = '{:.1f}%'.format(100 * p.get_height()/total) # percentage of each class of the category\n",
        "        x = p.get_x() + p.get_width() / 2 - 0.25 # width of the plot\n",
        "        y = p.get_y() + p.get_height()           # hieght of the plot\n",
        "        ax.annotate(percentage, (x, y), size = 14) # annotate the percantage \n",
        "        \n",
        "    plt.show() # show the plot"
      ],
      "metadata": {
        "id": "85A-oWzAI0kt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# While doing uni-variate analysis of numerical variables we want to study their central tendency \n",
        "# and dispersion.\n",
        "# Let us write a function that will help us create boxplot and histogram for any input numerical \n",
        "# variable.\n",
        "# This function takes the numerical column as the input and returns the boxplots \n",
        "# and histograms for the variable.\n",
        "\n",
        "def histogram_boxplot(feature, figsize=(15,10), bins = None):\n",
        "    \"\"\" Boxplot and histogram combined\n",
        "    feature: 1-d feature array\n",
        "    figsize: size of fig (default (9,8))\n",
        "    bins: number of bins (default None / auto)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2, # Number of rows of the subplot grid= 2\n",
        "                                           sharex = True, # x-axis will be shared among all subplots\n",
        "                                           gridspec_kw = {\"height_ratios\": (.25, .75)}, \n",
        "                                           figsize = figsize \n",
        "                                           ) # creating the 2 subplots\n",
        "    sns.boxplot(feature, ax=ax_box2, showmeans=True, color='violet') # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.distplot(feature, kde=F, ax=ax_hist2, bins=bins,palette=\"winter\") if bins else sns.distplot(feature, kde=False, ax=ax_hist2) # For histogram\n",
        "    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') # Add mean to the histogram\n",
        "    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') # Add median to the histogram"
      ],
      "metadata": {
        "id": "sTyvsheDI8lM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wBqNSZ28JAVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}